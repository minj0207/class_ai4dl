{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMUJq8WoIfum"
      },
      "source": [
        "# 7장 케라스 모델 활용법"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgO9yXd0Ifuo"
      },
      "source": [
        "**감사말**: 프랑소와 숄레의 [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff) 7장에 사용된 코드에 대한 설명을 담고 있으며 텐서플로우 2.6 버전에서 작성되었습니다. 소스코드를 공개한 저자에게 감사드립니다.\n",
        "\n",
        "**tensorflow 버전과 GPU 확인**\n",
        "- 구글 코랩 설정: '런타임 -> 런타임 유형 변경' 메뉴에서 GPU 지정 후 아래 명령어 실행 결과 확인\n",
        "\n",
        "    ```\n",
        "    !nvidia-smi\n",
        "    ```\n",
        "\n",
        "- 사용되는 tensorflow 버전 확인\n",
        "\n",
        "    ```python\n",
        "    import tensorflow as tf\n",
        "    tf.__version__\n",
        "    ```\n",
        "- tensorflow가 GPU를 사용하는지 여부 확인\n",
        "\n",
        "    ```python\n",
        "    tf.config.list_physical_devices('GPU')\n",
        "    ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVvoNgUmIfup"
      },
      "source": [
        "## 주요 내용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2TIL8E4Ifup"
      },
      "source": [
        "- 모델 구성법\n",
        "- 모델 훈련 모니터링\n",
        "- 사용자 정의 모델 훈련 및 평가"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFfLmFizIfuq"
      },
      "source": [
        "## 7.1 케라스 활용성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNGzSX4cIfuq"
      },
      "source": [
        "케라스를 이용하여 매우 단순한 모델부터 매우 복잡한 모델까지 구성 및 훈련이 가능하다. \n",
        "케라스의 모델과 층은 모두 각각 `Model` 클래스와 `Layer` 클래스를 상속하기에 \n",
        "다른 모델에서 사용된 요소들을 재활용하기에도 용이하다.\n",
        "\n",
        "여기서는 주어진 문제에 따른 케라스 모델 구성법과 훈련법의 다양한 방식을 살펴본다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z63A2bsWIfuq"
      },
      "source": [
        "## 7.2 케라스 모델 구성법"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eisS5RRoIfuq"
      },
      "source": [
        "케라스를 이용하여 모델을 세 가지 방식으로 구성할 수 있다.\n",
        "\n",
        "- `Sequential` 모델: 층으로 스택을 쌓아 만든 모델\n",
        "- 함수형 API 활용: 가장 많이 사용됨.\n",
        "- 모델 서브클래싱: 모든 것을 사용자가 지정.\n",
        "\n",
        "가장 간단한 모델부터 아주 복잡한 모델까지 모두 구성할 수 있으며\n",
        "사용자가 직접 정의한 모델과 레이어도 활용할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbohLkT4Ifur"
      },
      "source": [
        "### 모델 구성법 1: `Sequential` 모델"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Qyf3tf6Ifur"
      },
      "source": [
        "층으로 스택을 쌓아 만든 모델이며 가장 단순하다.\n",
        "\n",
        "- 하나의 입력값과 하나의 출력값만 사용 가능\n",
        "- 층을 지정된 순서대로만 적용 가능"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29o8wjI3Ifur"
      },
      "source": [
        "**`Sequential` 클래스**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HBbboATLIfur"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoTv_GH_Ifus"
      },
      "source": [
        "층의 추가는 `add` 메서드를 이용할 수도 있다.\n",
        "더해진 순서대로 층이 쌓인다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2xATjnYBIfut"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential()\n",
        "model.add(layers.Dense(64, activation=\"relu\"))\n",
        "model.add(layers.Dense(10, activation=\"softmax\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAzHGDP8Ifut"
      },
      "source": [
        "**`build()` 메서드**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7ctqEdeIfut"
      },
      "source": [
        "모델 훈련에 사용되는 층별 가중치는 모델이 처음 활용될 때 호출되는\n",
        "`build()` 메서드에 의해 초기화된다.\n",
        "이유는 입력값이 들어와야 가중치 텐서의 모양(shape)을 정할 수 있기 때문이다. \n",
        "아래 코드 샘플은 [3장](https://codingalzi.github.io/dlp/notebooks/dlp03_introduction_to_keras_and_tf.html)에서 \n",
        "`SimpleDense`를 선언할 때 사용된 `build()` 메서드를 보여주며,\n",
        "훈련이 시작되면서 첫 배치 데이터셋이 입력될 때 특성 수를 확인하여\n",
        "가중치와 편향 텐서를 생성과 동시에 초기화한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWqpp9VJIfuu"
      },
      "source": [
        "```python\n",
        "def build(self, input_shape):\n",
        "    input_dim = input_shape[-1]   # 입력 샘플의 특성 수\n",
        "    self.W = self.add_weight(shape=(input_dim, self.units),\n",
        "                             initializer=\"random_normal\")\n",
        "    self.b = self.add_weight(shape=(self.units,),\n",
        "                             initializer=\"zeros\")\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3kpNJS8Ifuu"
      },
      "source": [
        "따라서 지금 당장 가중치를 확인하려 하면 오류가 발생한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wDTKfZOIfuu"
      },
      "source": [
        "```python\n",
        ">>> model.weights\n",
        "...\n",
        "ValueError: Weights for model sequential_1 have not yet been created. \n",
        "Weights are created when the Model is first called on inputs or \n",
        "`build()` is called with an `input_shape`.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cV7qWTnzIfuu"
      },
      "source": [
        "반면에 입력값 대신 `build()` 메서드를 특성 수 정보를 이용하여 직접 호출하면\n",
        "가중치 텐서가 무작위로 초기화된 형식으로 생성된다.\n",
        "즉, **모델 빌드**가 완성된다.\n",
        "\n",
        "- `input_shape` 키워드 인자: `(None, 특성수)`\n",
        "- `None`은 임의의 크기의 배치도 다룰 수 있다는 것을 의미함."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cretbHklIfuv"
      },
      "outputs": [],
      "source": [
        "model.build(input_shape=(None, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llGvsvqvIfuv"
      },
      "source": [
        "모델 빌드가 완성되면 `weights` 속성에 생성된 모델 훈련에 필요한 모든 가중치와 편향이 저장된다.\n",
        "위 모델에 대해서 층별로 가중치와 편향 텐서 하나씩 총 4 개의 텐서가 생성된다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DfLYFYs2Ifuv",
        "outputId": "4db66739-bbed-4b76-cc6e-dd97101b472d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "len(model.weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwGTn6RqIfuv"
      },
      "source": [
        "- 1층의 가중치와 편향 텐서"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c55EcFfcIfuw",
        "outputId": "6f7ec304-73ca-4c05-8ceb-f10068709d1d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([3, 64])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.weights[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qACUnO57Ifuw",
        "outputId": "08c3f36d-b823-47ef-e3d5-a6ec0029fc46"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([64])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.weights[1].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqA7GUg7Ifuw"
      },
      "source": [
        "- 2층의 가중치와 편향 텐서"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_yseQBVIfuw",
        "outputId": "93c3178c-f9a3-4155-f760-13eef7b9e6f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([64, 10])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.weights[2].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jPns8i6Ifuw",
        "outputId": "7cbf5d27-aee2-43da-8c71-c2206704df3d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([10])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.weights[3].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zgFB8e9Ifuw"
      },
      "source": [
        "**`summary()` 메서드**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9-T1FouIfux"
      },
      "source": [
        "완성된 모델의 요악한 내용은 확인할 수 있다.\n",
        "\n",
        "- 모델과 층의 이름\n",
        "- 층별 파라미터 수\n",
        "- 파라미터 수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTjRVnnOIfux",
        "outputId": "eda67642-547e-4ca6-99dc-9c150c42ef6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 906\n",
            "Trainable params: 906\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHX2cSZtIfux"
      },
      "source": [
        "**`name` 인자**\n",
        "\n",
        "모델 또는 층을 지정할 때 생성자 메서등의 `name` 키워드 인자를 이용하여 이름을 지정할 수도 있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3IvJXnMyIfux",
        "outputId": "f89187b4-299d-40a6-9f27-39e9ebbb7063"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"my_example_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "my_first_layer (Dense)       (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "my_last_layer (Dense)        (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 906\n",
            "Trainable params: 906\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = keras.Sequential(name=\"my_example_model\")\n",
        "model.add(layers.Dense(64, activation=\"relu\", name=\"my_first_layer\"))\n",
        "model.add(layers.Dense(10, activation=\"softmax\", name=\"my_last_layer\"))\n",
        "\n",
        "model.build((None, 3))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvLaB1AFIfux"
      },
      "source": [
        "**`Input()` 함수, `KerasTensor`, 모델 디버깅**\n",
        "\n",
        "모델 구성 중간에 구성 과정을 확인하려면 `Input()`함수를 이용하여\n",
        "**케라스텐서**(`KerasTensor`) 객체를\n",
        "가장 먼저 모델에 추가한다.\n",
        "그러면 층을 추가할 때마다 `summary()`를 실행할 수 있다.\n",
        "`Input()` 함수는 모델 훈련에 사용되는 데이터 샘플의 모양(shape) 정보를 제공하는 \n",
        "    가상의 텐서인 `KerasTensor` 객체를 생성한다.\n",
        "    \n",
        "**주의사항**: `shape` 키워드 인자에 사용되는 값은 각 샘플의 특성 수이며,\n",
        "앞서 `build()` 메서드의 인자와 다른 형식으로 사용된다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmrrvT45Ifux"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.Input(shape=(3,)))\n",
        "model.add(layers.Dense(64, activation=\"relu\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlBT_0xnIfuy",
        "outputId": "d99ce29d-8972-482c-eb4e-6b4ac402a142"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 64)                256       \n",
            "=================================================================\n",
            "Total params: 256\n",
            "Trainable params: 256\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AyXV6EZeIfuy",
        "outputId": "43597093-982c-40d5-fa2d-3328287412dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 906\n",
            "Trainable params: 906\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.add(layers.Dense(10, activation=\"softmax\"))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lupgfO8gIfuy"
      },
      "source": [
        "### 모델 구성법 2: 함수형 API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SaBkcbyIfuy"
      },
      "source": [
        "다중 입력과 다중 출력을 지원하려면 함수형 API를 활용하여 모델을 구성해야 하며,\n",
        "가장 많이 사용되는 모델 구성법이다. \n",
        "사용법은 간단하다.\n",
        "\n",
        "```python\n",
        "Model(inputs, outputs)\n",
        "```\n",
        "\n",
        "- `Model`: 케라사의 기본 모델 클래스\n",
        "- `inputs` 인자: 한 개 이상의 케라스텐서(`KerasTensor`) 객체 이루어진 리스트\n",
        "- `outputs` 인자: 한 개 이사의 출력층으로 이루어진 리스트"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2cF6VwPIfuy"
      },
      "source": [
        "#### 기본 활용법"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQUruZ0uIfuz"
      },
      "source": [
        "앞서 살펴 본 `Sequential` 모델을 함수형 API를 이용하여 구성하면 다음과 같다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-o1za52rIfuz"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(3,), name=\"my_input\")          # 입력층\n",
        "features = layers.Dense(64, activation=\"relu\")(inputs)     # 은닉층\n",
        "outputs = layers.Dense(10, activation=\"softmax\")(features) # 출력층\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZnq1bBAIfuz"
      },
      "source": [
        "사용된 단계들을 하나씩 살펴보자."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WApAbLjcIfuz"
      },
      "source": [
        "- 입력층: `inputs = keras.Input(shape=(3,), name=\"my_input\")`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94Ns1b3hIfuz"
      },
      "source": [
        "생성된 값은 `KerasTensor`이다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52BMVPcMIfuz",
        "outputId": "63310ce5-73cb-46f8-ed5f-f1ca78e2b7f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "keras.engine.keras_tensor.KerasTensor"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVux32brIfuz"
      },
      "source": [
        "케라스텐서(`KerasTensor`)의 모양에서 `None`은 배치 사이즈, 즉 \n",
        "하나의 훈련 스텝에 사용되는 샘플의 수를 대상으로 하며, \n",
        "임의의 크기의 배치를 처리할 수 있다는 의미로 사용된다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYogqUp6Ifuz",
        "outputId": "9cc42e47-0dfd-4f4c-a2e3-3e2f38d430f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([None, 3])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i61K4B5YIfu0",
        "outputId": "9a6a9f9e-1687-4bd7-bb1c-313edc905634"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tf.float32"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmzFyJhyIfu0"
      },
      "source": [
        "- 은닉층: `features = layers.Dense(64, activation=\"relu\")(inputs)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6UhkWPkOIfu0",
        "outputId": "4bd5a2fa-645f-4dd1-c743-18b6541ab778"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "keras.engine.keras_tensor.KerasTensor"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqCP5fUpIfu0",
        "outputId": "a54bedb5-edd2-45de-e3ff-179e79a6dfd2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([None, 64])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuCtPY31Ifu0"
      },
      "source": [
        "- 출력층: `outputs = layers.Dense(10, activation=\"softmax\")(features)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3NdDqGhIfu0",
        "outputId": "b9d46e7d-c93c-45b5-86f3-3ead67d2f2e8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "keras.engine.keras_tensor.KerasTensor"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUZb1nojIfu0"
      },
      "source": [
        "- 모델 빌드\n",
        "\n",
        "    ```pythoh\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aG7Aqe76Ifu0",
        "outputId": "f81ea7d0-ede5-4fc8-8c1d-55287702c2e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "my_input (InputLayer)        [(None, 3)]               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 906\n",
            "Trainable params: 906\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kGfUBwYIfu1"
      },
      "source": [
        "`KerasTensor`의 역할"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LP1KTsEqIfu1"
      },
      "source": [
        "앞서 보았듯이 케라스텐서는 모델 훈련에 사용되는 텐서의 모양에 대한 정보를 제공하는 \n",
        "**가상의 텐서**이다.\n",
        "빌드되는 모델은 입력 케라스텐서부터 출력 케라스텐서까지 각 층에 저장된 \n",
        "텐서의 모양 정보를 이용하여 가중치 텐서와 편향 텐서를 생성하고 초기화한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12SRlzZmIfu1"
      },
      "source": [
        "#### 다중 입력, 다중 출력 모델 구성법"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyU2yxZZIfu1"
      },
      "source": [
        "고객의 요구사항이 적힌 티켓을 처리할 때 필요한 우선순위와 담당부서를 지정하는 시스템을 구현하려 한다.\n",
        "시스템에 사용될 모델은 세 개의 입력과 두 개의 출력을 사용한다. \n",
        "\n",
        "- 입력\n",
        "    - `title`: 요구사항 타이틀. 문자열 인코딩. `vocabulary_size` 활용(11장에서 다룸).\n",
        "    - `text_body`: 요구사항 내용. 문자열 인코딩. `vocabulary_size` 활용(11장에서 다룸).\n",
        "    - `tags`: 사용자에 의한 추가 선택 사항. 멀티-핫-인코딩 사용.\n",
        "- 출력\n",
        "    - `priority`: 요구사항 처리 우선순위. 0에서 1사이의 값. 시그모이드(sigmoid) 활용.\n",
        "    - `department`: 요구사항 처리 담당 부서. 소프트맥스 활용."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtNK4X-ZIfu1"
      },
      "outputs": [],
      "source": [
        "vocabulary_size = 10000    # 요구사항에 사용되는 단어 총 수\n",
        "num_tags = 100             # 태그 수\n",
        "num_departments = 4        # 부서 수\n",
        "\n",
        "# 입력층: 세 개\n",
        "title = keras.Input(shape=(vocabulary_size,), name=\"title\")\n",
        "text_body = keras.Input(shape=(vocabulary_size,), name=\"text_body\")\n",
        "tags = keras.Input(shape=(num_tags,), name=\"tags\")\n",
        "\n",
        "# 은닉층\n",
        "features = layers.Concatenate()([title, text_body, tags]) # shape=(None, 10000+10000+100)\n",
        "features = layers.Dense(64, activation=\"relu\")(features)\n",
        "\n",
        "# 출력층: 두 개\n",
        "priority = layers.Dense(1, activation=\"sigmoid\", name=\"priority\")(features)\n",
        "department = layers.Dense(\n",
        "    num_departments, activation=\"softmax\", name=\"department\")(features)\n",
        "\n",
        "# 모델 빌드\n",
        "model = keras.Model(inputs=[title, text_body, tags], outputs=[priority, department])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbTP_etbIfu1"
      },
      "source": [
        "모델 훈련을 위해 적절한 개수의 입력 텐서와 타깃 텐서를 지정해야 한다.\n",
        "여기서는 훈련 과정을 설명하기 위해 \n",
        "적절한 모양의 입력 텐서 3개와 타깃 텐서 2개를 무작위로 생성해서 사용한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUgWqa_EIfu1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 샘플 수\n",
        "num_samples = 1280\n",
        "\n",
        "# 입력 텐서 3 개 무작위 생성\n",
        "title_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
        "text_body_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
        "tags_data = np.random.randint(0, 2, size=(num_samples, num_tags))    # 멀티-핫-인코딩\n",
        "\n",
        "# 타깃 텐서 2 개 무작위 생성\n",
        "priority_data = np.random.random(size=(num_samples, 1))\n",
        "department_data = np.random.randint(0, 2, size=(num_samples, num_departments))  # 멀티-핫-인코딩"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUCl55L2Ifu1"
      },
      "source": [
        "모델 컴파일 과정에서 지정된 타깃 수만큼 손실함수와 측정 기준을 지정해야 한다.\n",
        "\n",
        "- 손실함수(loss)\n",
        "    - `priority` 대상: `mean_squared_error`\n",
        "    - `department` 대상: `categorical_crossentropy`\n",
        "- 평가지표(metrics): 평가지표는 여러 개를 사용할 수 있기에 대상 별로 리스트로 지정함.\n",
        "    - `priority` 대상: `[\"mean_absolute_error\"]`\n",
        "    - `department` 대상: `[\"accuracy\"]`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMQl5XNWIfu2"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=\"adam\",\n",
        "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
        "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgL3kqGUIfu2"
      },
      "source": [
        "모델 훈련은 `fit()` 함수에 세 개의 훈련 텐서로 이루어진 리스트와 \n",
        "두 개의 타깃 텐서로 이루어진 리스트를 지정한 후에 실행한다. \n",
        "여기서는 시험삼아 한 번의 에포크만 사용한다.\n",
        "\n",
        "- `epochs=1`\n",
        "- `batch_size=None`: 배치 크기를 지정하지 않으면 32개로 자동 지정됨.\n",
        "    그래서 스텝수가 40(= 1280/30)이 된다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5m_iKtpyIfu2",
        "outputId": "e459fa8c-28d3-418c-f11f-94f501a800fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "40/40 [==============================] - 1s 6ms/step - loss: 7.9958 - priority_loss: 0.3332 - department_loss: 7.6626 - priority_mean_absolute_error: 0.5019 - department_accuracy: 0.2047\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fafd076b8e0>"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit([title_data, text_body_data, tags_data],\n",
        "          [priority_data, department_data],\n",
        "          epochs=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MC_HJFk-Ifu2"
      },
      "source": [
        "평가도 훈련과 동일한 방식의 인자가 사용된다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tfk5f8puIfu2",
        "outputId": "e1cb0ebe-2fb8-43d4-e870-e07c98fadca7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "40/40 [==============================] - 0s 3ms/step - loss: 14.5559 - priority_loss: 0.3365 - department_loss: 14.2194 - priority_mean_absolute_error: 0.5046 - department_accuracy: 0.2484\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[14.555928230285645,\n",
              " 0.33653491735458374,\n",
              " 14.219395637512207,\n",
              " 0.5045641660690308,\n",
              " 0.24843749403953552]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate([title_data, text_body_data, tags_data],\n",
        "               [priority_data, department_data])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5B1EAnajIfu2"
      },
      "source": [
        "예측은 입력값만 리스트로 지정하고 실행하면 두 개의 어레이 출력값으로 구성된 리스트가 반환된다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kO8JuYZVIfu2"
      },
      "outputs": [],
      "source": [
        "priority_preds, department_preds = model.predict([title_data, text_body_data, tags_data])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vF8La_qVIfu2",
        "outputId": "f1e3298c-eef3-439b-dbad-1f6c269ffd85"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       ...,\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.]], dtype=float32)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "priority_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fxvEh59Ifu2",
        "outputId": "2fa37d45-87fe-4660-9bc6-ab95209deec5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[3.3588567e-08, 7.5205421e-01, 5.2188020e-06, 2.4794061e-01],\n",
              "       [1.2007128e-07, 7.7444011e-01, 5.9996864e-06, 2.2555383e-01],\n",
              "       [1.5187045e-07, 2.8277490e-01, 9.5683536e-06, 7.1721542e-01],\n",
              "       ...,\n",
              "       [1.6659516e-08, 9.1552025e-01, 1.3529956e-06, 8.4478483e-02],\n",
              "       [3.0281532e-07, 5.5916554e-01, 7.0887222e-06, 4.4082704e-01],\n",
              "       [6.5539444e-07, 3.2640365e-01, 4.6442925e-05, 6.7354923e-01]],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "department_preds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIc2ZrCcIfu3"
      },
      "source": [
        "**사전 객체 활용**\n",
        "\n",
        "입력층과 출력층의 이름을 이용하여 사전 형식으로 입력값과 출력값을 지정할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjHRJ4VEIfu3",
        "outputId": "fb9c93a9-eacb-4d55-a881-29423eb4a6c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "40/40 [==============================] - 1s 6ms/step - loss: 7.8852 - priority_loss: 0.3365 - department_loss: 7.5487 - priority_mean_absolute_error: 0.5046 - department_accuracy: 0.2859\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 4.0846 - priority_loss: 0.3365 - department_loss: 3.7480 - priority_mean_absolute_error: 0.5046 - department_accuracy: 0.1852\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer=\"adam\",\n",
        "              loss={\"priority\": \"mean_squared_error\", \"department\": \"categorical_crossentropy\"},\n",
        "              metrics={\"priority\": [\"mean_absolute_error\"], \"department\": [\"accuracy\"]})\n",
        "\n",
        "model.fit({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
        "          {\"priority\": priority_data, \"department\": department_data},\n",
        "          epochs=1)\n",
        "\n",
        "model.evaluate({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
        "               {\"priority\": priority_data, \"department\": department_data})\n",
        "\n",
        "priority_preds, department_preds = model.predict(\n",
        "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XQ31P01Ifu3"
      },
      "source": [
        "#### 층 연결 구조 확인"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-uAosG8Ifu3"
      },
      "source": [
        "`plot_model()`을 이용하여 층 연결 구조를 그래프로 나타낼 수 있다.\n",
        "\n",
        "```python\n",
        ">>> keras.utils.plot_model(model, \"ticket_classifier.png\")\n",
        "```\n",
        "\n",
        "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/ticket_classifier.png\" style=\"width:400px;\"></div>\n",
        "\n",
        "**주의사항**: `pydot` 파이썬 모듈과 graphviz 라는 프로그램이 컴퓨터에 설치되어 있어야 한다.\n",
        "\n",
        "- `pydot` 모듈 설치: `pip install pydot`\n",
        "- graphviz 프로그램 설치: [https://graphviz.gitlab.io/download/](https://graphviz.gitlab.io/download/)\n",
        "- 구글 코랩에서 기본으로 지원됨."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cE8b8uoKIfu3"
      },
      "source": [
        "입력 텐서와 출력 텐서의 모양을 함께 표기할 수도 있다.\n",
        "\n",
        "```python\n",
        ">>> keras.utils.plot_model(model, \"ticket_classifier_with_shape_info.png\", show_shapes=True)\n",
        "```\n",
        "\n",
        "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/ticket_classifier_with_shapes.png\" style=\"width:900px;\"></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynUJ1-mnIfu3"
      },
      "source": [
        "#### 모델 재활용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfkUBQ-WIfu3"
      },
      "source": [
        "훈련된 모델의 특성을 이용하여 새로운 모델을 빌드할 수 있다.\n",
        "먼저 모델의 `layers` 속성을 이용하여 사용된 층에 대한 정보를 확인한다. \n",
        "`layers` 속성은 사용된 층들의 객체로 이루어진 리스트를 가리킨다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-Ou28qdIfu3",
        "outputId": "b6b3cfe3-6411-49bb-85c2-d9faac96352e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<keras.engine.input_layer.InputLayer at 0x7fafe2058160>,\n",
              " <keras.engine.input_layer.InputLayer at 0x7fafe20581c0>,\n",
              " <keras.engine.input_layer.InputLayer at 0x7fafe2058190>,\n",
              " <keras.layers.merge.Concatenate at 0x7fafe2058610>,\n",
              " <keras.layers.core.Dense at 0x7fafe2035580>,\n",
              " <keras.layers.core.Dense at 0x7fafe2058c10>,\n",
              " <keras.layers.core.Dense at 0x7fafe20267f0>]"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Df3YkY4Ifu4"
      },
      "source": [
        "예를 들어, 3번 인덱스에 해당하는 층의 입력값과 출력값에 대한 정보는 아래처럼 확인할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PDaHpDSIfu4",
        "outputId": "55fade05-1b6d-4f16-f37f-11ffd5a0194e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'title')>,\n",
              " <KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'text_body')>,\n",
              " <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'tags')>]"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.layers[3].input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4Z4t23gIfu4",
        "outputId": "dc41392f-2a7e-4eaf-c89c-2a3d05bab2e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 20100) dtype=float32 (created by layer 'concatenate')>"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.layers[3].output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EScNoipCIfu4"
      },
      "source": [
        "출력층을 제외한 나머지 층을 재활용해보자.\n",
        "출력층은 5번과 6번 인덱스에 위치하기에 4번 인덱스가\n",
        "가리키는 (은닉)층의 출력 정보를 따로 떼어낸다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yN95dFt6Ifu4"
      },
      "outputs": [],
      "source": [
        "features = model.layers[4].output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGVDun1cIfu4"
      },
      "source": [
        "이제 출력층에 문제해결의 어려움 정도를 \"quick\", \"medium\", \"difficult\"로\n",
        "구분하는 어려움(difficulty) 정도를 판별하는 층을 추가해보자.\n",
        "먼저, `difficulty` 층을 준비한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUqjwlGpIfu4"
      },
      "outputs": [],
      "source": [
        "difficulty = layers.Dense(3, activation=\"softmax\", name=\"difficulty\")(features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SkBkrKlIfu4"
      },
      "source": [
        "준비된 `'difficulty'` 층을 출력층으로 추가하여 \n",
        "`priority`, `department`, `difficulty`\n",
        "세 개의 출력값을 생성하는 새로운 모델을 구성한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfXpfZtfIfu4"
      },
      "outputs": [],
      "source": [
        "new_model = keras.Model(\n",
        "    inputs=[title, text_body, tags],\n",
        "    outputs=[priority, department, difficulty])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcmVq4-xIfu4"
      },
      "source": [
        "새로 생성된 모델은 기존에 훈련된 모델의 가중치,\n",
        "즉, 은닉층에 사용된 가중치는 그대로 사용되며,\n",
        "모델 구성 그래프는 다음과 같다.\n",
        "\n",
        "```python\n",
        ">>> keras.utils.plot_model(new_model, \"updated_ticket_classifier.png\", show_shapes=True)\n",
        "```\n",
        "\n",
        "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/updated_ticket_classifier.png\" style=\"width:900px;\"></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sy7bhBUNIfu5"
      },
      "source": [
        "요약 결과는 다음과 같다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yG1zZb8_Ifu5",
        "outputId": "1fdcc725-a716-4059-f47f-3aa2cc1620af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "title (InputLayer)              [(None, 10000)]      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "text_body (InputLayer)          [(None, 10000)]      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tags (InputLayer)               [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 20100)        0           title[0][0]                      \n",
            "                                                                 text_body[0][0]                  \n",
            "                                                                 tags[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 64)           1286464     concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "priority (Dense)                (None, 1)            65          dense_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "department (Dense)              (None, 4)            260         dense_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "difficulty (Dense)              (None, 3)            195         dense_8[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 1,286,984\n",
            "Trainable params: 1,286,984\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "new_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KORuYDXfIfu5"
      },
      "source": [
        "### 모델 구성법 3: 서브클래싱"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MI0WZQjcIfu5"
      },
      "source": [
        "케라스 모델과 호환되는 모델 클래스를 직접 선언하여 활용하려면 `keras.Model` 클래스를 상속해야 한다.\n",
        "이런 방식을 **서브클래싱**(subclassing)이라 부르며\n",
        "`keras.Model` 클래스를 상속하면서 기본적으로 아래 두 메서드를 목적에 맞추어 재정의(overriding)하면 된다.\n",
        "\n",
        "- `__init__()` 메서드(생성자): 은닉층과 출력층의 구성요소 지정\n",
        "- `call()` 메서드: 모델 구성 후 출력값 반환\n",
        "\n",
        "앞서 함수형 API로 구성한 티켓 모델을 서브클래싱을 기법을 이용하여 구현하면 다음과 같다.\n",
        "\n",
        "**참고**: `keras.layers.Layer`를 상속하여 사용자 정의 층을 선언하는 방식과 거의 유사하다([3장 6절](https://codingalzi.github.io/dlp/notebooks/dlp03_introduction_to_keras_and_tf.html) 참조)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6HyGWZ0Ifu5"
      },
      "outputs": [],
      "source": [
        "class CustomerTicketModel(keras.Model):\n",
        "\n",
        "    def __init__(self, num_departments):\n",
        "        super().__init__()\n",
        "        self.concat_layer = layers.Concatenate()\n",
        "        self.mixing_layer = layers.Dense(64, activation=\"relu\")\n",
        "        self.priority_scorer = layers.Dense(1, activation=\"sigmoid\")\n",
        "        self.department_classifier = layers.Dense(\n",
        "            num_departments, activation=\"softmax\")\n",
        "\n",
        "    def call(self, inputs):               # inputs: 사전 객체 입력값. 모양은 미정.\n",
        "        title = inputs[\"title\"]\n",
        "        text_body = inputs[\"text_body\"]\n",
        "        tags = inputs[\"tags\"]\n",
        "\n",
        "        features = self.concat_layer([title, text_body, tags])    # 은닉층\n",
        "        features = self.mixing_layer(features)\n",
        "        priority = self.priority_scorer(features)                 # 출력층\n",
        "        department = self.department_classifier(features)\n",
        "        return priority, department                               # outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8V298pIqIfu5"
      },
      "source": [
        "모델 구성은 해당 모델의 객체를 생성하면 된다.\n",
        "다만 `Layer`의 경우처럼 가중치는 실제 데이터와 함께 호출되지 전까지 생성되지 않는다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFx8rZc7Ifu5",
        "outputId": "f81eb3d6-741d-45f7-b850-f4d28ca89ab0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = CustomerTicketModel(num_departments=4)\n",
        "\n",
        "model.weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9NxRT7pIfu5"
      },
      "source": [
        "컴파일, 훈련, 평가, 예측은 이전과 완전히 동일한 방식으로 실행된다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_W5R82SIfu5",
        "outputId": "e532bf2e-e929-4047-aa3a-657045b6bb0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "40/40 [==============================] - 1s 6ms/step - loss: 8.1189 - output_1_loss: 0.3152 - output_2_loss: 7.8037 - output_1_mean_absolute_error: 0.4834 - output_2_accuracy: 0.2414\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 3.8896 - output_1_loss: 0.3274 - output_2_loss: 3.5622 - output_1_mean_absolute_error: 0.4954 - output_2_accuracy: 0.4742\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer=\"adam\",\n",
        "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
        "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
        "model.fit({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
        "          [priority_data, department_data],\n",
        "          epochs=1)\n",
        "model.evaluate({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
        "               [priority_data, department_data])\n",
        "priority_preds, department_preds = model.predict(\n",
        "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GTC8PvsIfu6"
      },
      "source": [
        "**서브클래싱 기법의 장단점**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da6101d7Ifu6"
      },
      "source": [
        "- 장점\n",
        "    - `call()` 함수를 이용하여 층을 임의로 구성할 수 있다.\n",
        "    - 파이썬 프로그래밍 관련 모든 기법을 적용할 수 있다.\n",
        "- 단점\n",
        "    - 모델 구성을 전적으로 책임져야 한다.\n",
        "    - 모델 구성 정보가 `call()` 함수 외부로 노출되지 않아서\n",
        "        앞서 보았던 그래프 표현을 사용할 수 없다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQWElSYVIfu6"
      },
      "source": [
        "### 모델 구성법 혼합"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1UWCZrFIfu6"
      },
      "source": [
        "소개된 세 가지 방식을 임의로 혼합하여 활용할 수 있다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86jOq4TnIfu6"
      },
      "source": [
        "**예제: 서브클래싱 모델을 함수형 모델에 활용하기** (강추!!!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygVw_eiFIfu6"
      },
      "outputs": [],
      "source": [
        "class Classifier(keras.Model):\n",
        "\n",
        "    def __init__(self, num_classes=2):\n",
        "        super().__init__()\n",
        "        if num_classes == 2:\n",
        "            num_units = 1\n",
        "            activation = \"sigmoid\"\n",
        "        else:\n",
        "            num_units = num_classes\n",
        "            activation = \"softmax\"\n",
        "        self.dense = layers.Dense(num_units, activation=activation)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.dense(inputs)\n",
        "\n",
        "inputs = keras.Input(shape=(3,))\n",
        "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
        "outputs = Classifier(num_classes=10)(features)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ts3ilILsIfu6"
      },
      "source": [
        "**예제: 함수형 모델을 서브클래싱 모델에 활용하기**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-EqySZ7RIfu6"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(64,))\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(inputs)\n",
        "binary_classifier = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "class MyModel(keras.Model):\n",
        "\n",
        "    def __init__(self, num_classes=2):\n",
        "        super().__init__()\n",
        "        self.dense = layers.Dense(64, activation=\"relu\")\n",
        "        self.classifier = binary_classifier\n",
        "\n",
        "    def call(self, inputs):\n",
        "        features = self.dense(inputs)\n",
        "        return self.classifier(features)\n",
        "\n",
        "model = MyModel()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YW6QlFtIfu6"
      },
      "source": [
        "## 7.3 훈련 모니터링"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10jUb8ElIfu6"
      },
      "source": [
        "케라스 모델의 구성, 훈련, 평가, 예측은 정해진 방식으로 차례대로 이루어진다.\n",
        "아래 코드는 MNIST 데이터셋을 이용한 모델 훈련 전반 과정을 보여준다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q43EExvrIfu7",
        "outputId": "26c54d6b-e781-440a-c351-b13ae49c7d33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2953 - accuracy: 0.9119 - val_loss: 0.1480 - val_accuracy: 0.9579\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1671 - accuracy: 0.9527 - val_loss: 0.1220 - val_accuracy: 0.9684\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1412 - accuracy: 0.9613 - val_loss: 0.1125 - val_accuracy: 0.9711\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.1069 - accuracy: 0.9717\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "def get_mnist_model():\n",
        "    inputs = keras.Input(shape=(28 * 28,))\n",
        "    features = layers.Dense(512, activation=\"relu\")(inputs)\n",
        "    features = layers.Dropout(0.5)(features)\n",
        "    outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "(images, labels), (test_images, test_labels) = mnist.load_data()\n",
        "images = images.reshape((60000, 28 * 28)).astype(\"float32\") / 255\n",
        "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255\n",
        "train_images, val_images = images[10000:], images[:10000]\n",
        "train_labels, val_labels = labels[10000:], labels[:10000]\n",
        "\n",
        "model = get_mnist_model()\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(train_images, train_labels,\n",
        "          epochs=3,\n",
        "          validation_data=(val_images, val_labels))\n",
        "test_metrics = model.evaluate(test_images, test_labels)\n",
        "predictions = model.predict(test_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nx1L3x-hIfu7"
      },
      "source": [
        "### 사용자 정의 평가지표(`metrics`) 활용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7CtAmnOIfu7"
      },
      "source": [
        "**`Metric` 클래스 상속**\n",
        "\n",
        "아래 세 개의 메서드를 재정의(overriding)해야 한다.\n",
        "\n",
        "- `update_state()`\n",
        "- `result()`\n",
        "- `reset_state()`\n",
        "\n",
        "아래 코드는 평균제곱근오차(RMSE)를 평가지표로 사용하는 클래스를 \n",
        "이용하는 모델 훈련을 소개한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbBUtBjoIfu7"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class RootMeanSquaredError(keras.metrics.Metric):\n",
        "\n",
        "    def __init__(self, name=\"rmse\", **kwargs):\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self.mse_sum = self.add_weight(name=\"mse_sum\", initializer=\"zeros\")\n",
        "        self.total_samples = self.add_weight(\n",
        "            name=\"total_samples\", initializer=\"zeros\", dtype=\"int32\")\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        y_true = tf.one_hot(y_true, depth=tf.shape(y_pred)[1])\n",
        "        mse = tf.reduce_sum(tf.square(y_true - y_pred))\n",
        "        self.mse_sum.assign_add(mse)\n",
        "        num_samples = tf.shape(y_pred)[0]\n",
        "        self.total_samples.assign_add(num_samples)\n",
        "\n",
        "    def result(self):\n",
        "        return tf.sqrt(self.mse_sum / tf.cast(self.total_samples, tf.float32))\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.mse_sum.assign(0.)\n",
        "        self.total_samples.assign(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14ladKa1Ifu7",
        "outputId": "5b3981be-a25c-473a-d871-1f4f6c218e84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.2935 - accuracy: 0.9141 - rmse: 7.1828 - val_loss: 0.1709 - val_accuracy: 0.9510 - val_rmse: 7.3536\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1676 - accuracy: 0.9530 - rmse: 7.3561 - val_loss: 0.1227 - val_accuracy: 0.9657 - val_rmse: 7.4048\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1410 - accuracy: 0.9623 - rmse: 7.3852 - val_loss: 0.1244 - val_accuracy: 0.9691 - val_rmse: 7.4222\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.1120 - accuracy: 0.9711 - rmse: 7.4363\n"
          ]
        }
      ],
      "source": [
        "model = get_mnist_model()\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\", RootMeanSquaredError()])\n",
        "model.fit(train_images, train_labels,\n",
        "          epochs=3,\n",
        "          validation_data=(val_images, val_labels))\n",
        "test_metrics = model.evaluate(test_images, test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVcVH_qVIfu7"
      },
      "source": [
        "### 콜백(callback) 활용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KqeGmngIfu7"
      },
      "source": [
        "**콜백**(callback)은 모델 훈련 도중에 부가적으로 호출되는 객체이며\n",
        "학습 과정을 모니터링 하면서 일부 제어기능을 수행하는 다양한 메서드를 제공한다.\n",
        "콜백이 활용되는 주요 기능은 다음과 같다.\n",
        "\n",
        "- 모델 체크포인팅: 훈련 중 모델 상태 수시로 저장\n",
        "- 훈련 조기 중단: 검증셋 손실이 더 이상 개선되지 않는 경우 훈련 중단\n",
        "- 하이퍼 파라미터 조정: 학습률의 동적 변경\n",
        "- 훈련 기록 작성: 훈련셋 및 검증셋의 손실값, 평가지표 등 기록 및 시각화\n",
        "\n",
        "```python\n",
        "keras.callbacks.ModelCheckpoint\n",
        "keras.callbacks.EarlyStopping\n",
        "keras.callbacks.LearningRateScheduler\n",
        "keras.callbacks.ReduceLROnPlateau\n",
        "keras.callbacks.CSVLogger\n",
        "```\n",
        "\n",
        "여기서는 `EarlyStopping`과 `ModelCheckpoint` 두 콜백의 기능을 살펴본다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYOWjdT-Ifu7"
      },
      "source": [
        "**`fit()` 메서드에서 `callbacks` 인자 사용하기**\n",
        "\n",
        "아래 코드에 사용된 옵션은 다음과 같다.\n",
        "\n",
        "- `EarlyStopping`: 검증셋에 대한 정확도가 2 에포크(epoch) 연속 개선되지 않을 때 훈련 종료\n",
        "- `ModelCheckpoint`: 매 에포크마다 훈련된 모델 저장. \n",
        "    `save_best_only=True`가 설정된 경우 검증셋에 대한 손실값이 가장 낮은 모델만 저장."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDJ1J9gnIfu7"
      },
      "outputs": [],
      "source": [
        "callbacks_list = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_accuracy\",\n",
        "        patience=2,\n",
        "    ),\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"checkpoint_path.keras\",\n",
        "        monitor=\"val_loss\",\n",
        "        save_best_only=True,\n",
        "    )\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKrJNY5AIfu8",
        "outputId": "87a3673c-5a42-4657-dd01-7f949d748a65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2962 - accuracy: 0.9114 - val_loss: 0.1489 - val_accuracy: 0.9575\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1645 - accuracy: 0.9532 - val_loss: 0.1184 - val_accuracy: 0.9692\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1412 - accuracy: 0.9617 - val_loss: 0.1192 - val_accuracy: 0.9692\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1276 - accuracy: 0.9670 - val_loss: 0.1139 - val_accuracy: 0.9700\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1212 - accuracy: 0.9694 - val_loss: 0.1102 - val_accuracy: 0.9747\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1115 - accuracy: 0.9731 - val_loss: 0.1070 - val_accuracy: 0.9759\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1033 - accuracy: 0.9747 - val_loss: 0.1043 - val_accuracy: 0.9764\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1041 - accuracy: 0.9761 - val_loss: 0.1049 - val_accuracy: 0.9784\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0994 - accuracy: 0.9774 - val_loss: 0.1070 - val_accuracy: 0.9785\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0948 - accuracy: 0.9780 - val_loss: 0.1181 - val_accuracy: 0.9768\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fafaec86ee0>"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = get_mnist_model()\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(train_images, train_labels,\n",
        "          epochs=10,\n",
        "          callbacks=callbacks_list,\n",
        "          validation_data=(val_images, val_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSAgaFTyIfu8"
      },
      "source": [
        "조기종료 후 훈련과정에서 저장된 최고 성능의 모델을 불러오면 다음과 같다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYm314bHIfu8"
      },
      "outputs": [],
      "source": [
        "model = keras.models.load_model(\"checkpoint_path.keras\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDdrDsINIfu8"
      },
      "source": [
        "### 사용자 정의 콜백 활용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgN8MUFpIfu8"
      },
      "source": [
        "**`Callback` 클래스 상속**\n",
        "\n",
        "매 에포크와 매 배치 훈련 단계의 시작과 종료 지점에서\n",
        "수행해야 할 기능을 정의해야 하며 아래 메서드를 재정의하는 방식으로 이루어진다.\n",
        "\n",
        "```python\n",
        "on_epoch_begin(epoch, logs)\n",
        "on_epoch_end(epoch, logs)\n",
        "on_batch_begin(batch, logs)\n",
        "on_batch_end(batch, logs)\n",
        "on_train_begin(logs)\n",
        "on_train_end(logs)\n",
        "```\n",
        "\n",
        "각 메서드에 사용되는 인자는 훈련 과정 중에 자동으로 생성된 객체로부터 값을 받아온다.\n",
        "\n",
        "- `logs` 인자: 이전 배치와 에포크의 훈련셋과 검증셋에 대한 손실값, 평가지표 등을 포함한 사전 객체.\n",
        "- `batch`, `epoch`: 배치와 에포크 정보\n",
        "\n",
        "다음 `LossHistory` 콜백 클래스는 배치 훈련이 끝날 때마다 손실값을 저장하고\n",
        "에포크가 끝날 때마다 배치별 손실값을 그래프로 저장하여 훈련이 종료된 후 시각화하여 보여주도록 한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhY3HpRlIfu8"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "class LossHistory(keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs):\n",
        "        self.per_batch_losses = []\n",
        "\n",
        "    def on_batch_end(self, batch, logs):\n",
        "        self.per_batch_losses.append(logs.get(\"loss\"))\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs):\n",
        "        plt.clf()\n",
        "        plt.plot(range(len(self.per_batch_losses)), self.per_batch_losses,\n",
        "                 label=\"Training loss for each batch\")\n",
        "        plt.xlabel(f\"Batch (epoch {epoch})\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.legend()\n",
        "        plt.savefig(f\"plot_at_epoch_{epoch}\")\n",
        "        self.per_batch_losses = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DLPrgYbIfu8",
        "outputId": "6869c272-b494-48c2-cb26-01076d21cc8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2943 - accuracy: 0.9124 - val_loss: 0.1439 - val_accuracy: 0.9585\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1617 - accuracy: 0.9554 - val_loss: 0.1232 - val_accuracy: 0.9685\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1413 - accuracy: 0.9618 - val_loss: 0.1168 - val_accuracy: 0.9719\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1265 - accuracy: 0.9676 - val_loss: 0.1098 - val_accuracy: 0.9729\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1142 - accuracy: 0.9715 - val_loss: 0.1086 - val_accuracy: 0.9755\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1120 - accuracy: 0.9729 - val_loss: 0.1148 - val_accuracy: 0.9760\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1064 - accuracy: 0.9743 - val_loss: 0.1161 - val_accuracy: 0.9763\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1010 - accuracy: 0.9770 - val_loss: 0.1080 - val_accuracy: 0.9776\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0980 - accuracy: 0.9774 - val_loss: 0.1118 - val_accuracy: 0.9786\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0952 - accuracy: 0.9790 - val_loss: 0.1271 - val_accuracy: 0.9765\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fafe1f6af70>"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = get_mnist_model()\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(train_images, train_labels,\n",
        "          epochs=10,\n",
        "          callbacks=[LossHistory()],\n",
        "          validation_data=(val_images, val_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCJA500dIfu8"
      },
      "source": [
        "### 텐서보드(TensorBoard) 활용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oNJxsr4Ifu9"
      },
      "source": [
        "**텐서보드**(TensorBoard)는 모델 훈련과정을 모니터링하는 최고의 어플이며\n",
        "텐서플로우와 함께 기본적으로 설치된다.\n",
        "\n",
        "**주의사항**: 텐서보드 데이터의 저장경로를 \n",
        "\n",
        "```python\n",
        "/full_path_to_your_log_dir\n",
        "```\n",
        "\n",
        "대신에 \n",
        "\n",
        "```python\n",
        "./tensorboard_log_dir\n",
        "```\n",
        "\n",
        "등을 사용해야 리눅스, 맥 운영체제에서 오류가 발생하지 않는다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHJSFtWJIfu9",
        "outputId": "8115c400-40c7-491b-f893-6034699745fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2950 - accuracy: 0.9128 - val_loss: 0.1475 - val_accuracy: 0.9591\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1677 - accuracy: 0.9528 - val_loss: 0.1224 - val_accuracy: 0.9668\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1395 - accuracy: 0.9621 - val_loss: 0.1158 - val_accuracy: 0.9697\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1285 - accuracy: 0.9675 - val_loss: 0.1157 - val_accuracy: 0.9712\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1192 - accuracy: 0.9708 - val_loss: 0.1141 - val_accuracy: 0.9722\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1145 - accuracy: 0.9724 - val_loss: 0.1039 - val_accuracy: 0.9766\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1059 - accuracy: 0.9740 - val_loss: 0.1045 - val_accuracy: 0.9790\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1050 - accuracy: 0.9754 - val_loss: 0.1107 - val_accuracy: 0.9770\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0965 - accuracy: 0.9776 - val_loss: 0.1082 - val_accuracy: 0.9788\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0960 - accuracy: 0.9780 - val_loss: 0.1094 - val_accuracy: 0.9788\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fafb1441370>"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = get_mnist_model()\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "tensorboard = keras.callbacks.TensorBoard(\n",
        "    log_dir=\"./tensorboard_log_dir\",\n",
        ")\n",
        "\n",
        "model.fit(train_images, train_labels,\n",
        "          epochs=10,\n",
        "          validation_data=(val_images, val_labels),\n",
        "          callbacks=[tensorboard])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcUAQYBiIfu9"
      },
      "source": [
        "텐서보드를 주피터 노트북에서 아래처럼 실행할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "ryQ3IgOjIfu9",
        "outputId": "dd5569c7-e41d-4551-fbc8-a0301563394a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "      <iframe id=\"tensorboard-frame-4111b7461bd29e23\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
              "      </iframe>\n",
              "      <script>\n",
              "        (function() {\n",
              "          const frame = document.getElementById(\"tensorboard-frame-4111b7461bd29e23\");\n",
              "          const url = new URL(\"/\", window.location);\n",
              "          const port = 6006;\n",
              "          if (port) {\n",
              "            url.port = port;\n",
              "          }\n",
              "          frame.src = url;\n",
              "        })();\n",
              "      </script>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir ./tensorboard_log_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWvUvwc6Ifu9"
      },
      "source": [
        "텐서보드를 독립적으로 실행하여 훈련과정을 실시간으로 모니터링 하려면\n",
        "아래 명령어를 터미널 창에서 실행하고 반환된 주소로 접속하면 된다.\n",
        "\n",
        "```python\n",
        "tensorboard --logdir ./full_path_to_your_log_dir\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEGR0qsXIfu9"
      },
      "source": [
        "## 7.4 사용자 정의 훈련 알고리즘: `fit()` 메서드 대체"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6U1IyM9Ifu9"
      },
      "source": [
        "### Training versus inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ycIu8FVIfu9"
      },
      "source": [
        "### Low-level usage of metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2kCOkPkdIfu-"
      },
      "outputs": [],
      "source": [
        "metric = keras.metrics.SparseCategoricalAccuracy()\n",
        "targets = [0, 1, 2]\n",
        "predictions = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
        "metric.update_state(targets, predictions)\n",
        "current_result = metric.result()\n",
        "print(f\"result: {current_result:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SL6YCizvIfu-"
      },
      "outputs": [],
      "source": [
        "values = [0, 1, 2, 3, 4]\n",
        "mean_tracker = keras.metrics.Mean()\n",
        "for value in values:\n",
        "    mean_tracker.update_state(value)\n",
        "print(f\"Mean of values: {mean_tracker.result():.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vnf4yNHRIfu-"
      },
      "source": [
        "### A complete training and evaluation loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qak5NVclIfu-"
      },
      "source": [
        "**Writing a step-by-step training loop: the training step function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EE1lXW7BIfu-"
      },
      "outputs": [],
      "source": [
        "model = get_mnist_model()\n",
        "\n",
        "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
        "optimizer = keras.optimizers.RMSprop()\n",
        "metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
        "loss_tracking_metric = keras.metrics.Mean()\n",
        "\n",
        "def train_step(inputs, targets):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(inputs, training=True)\n",
        "        loss = loss_fn(targets, predictions)\n",
        "    gradients = tape.gradient(loss, model.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
        "\n",
        "    logs = {}\n",
        "    for metric in metrics:\n",
        "        metric.update_state(targets, predictions)\n",
        "        logs[metric.name] = metric.result()\n",
        "\n",
        "    loss_tracking_metric.update_state(loss)\n",
        "    logs[\"loss\"] = loss_tracking_metric.result()\n",
        "    return logs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwoB5_hRIfu-"
      },
      "source": [
        "**Writing a step-by-step training loop: resetting the metrics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHNHb2heIfu-"
      },
      "outputs": [],
      "source": [
        "def reset_metrics():\n",
        "    for metric in metrics:\n",
        "        metric.reset_state()\n",
        "    loss_tracking_metric.reset_state()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_V1UU0-TIfu-"
      },
      "source": [
        "**Writing a step-by-step training loop: the loop itself**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulsB2jCUIfu-"
      },
      "outputs": [],
      "source": [
        "training_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "training_dataset = training_dataset.batch(32)\n",
        "epochs = 3\n",
        "for epoch in range(epochs):\n",
        "    reset_metrics()\n",
        "    for inputs_batch, targets_batch in training_dataset:\n",
        "        logs = train_step(inputs_batch, targets_batch)\n",
        "    print(f\"Results at the end of epoch {epoch}\")\n",
        "    for key, value in logs.items():\n",
        "        print(f\"...{key}: {value:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPuD94vjIfu-"
      },
      "source": [
        "**Writing a step-by-step evaluation loop**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSaVc0f8Ifu_"
      },
      "outputs": [],
      "source": [
        "def test_step(inputs, targets):\n",
        "    predictions = model(inputs, training=False)\n",
        "    loss = loss_fn(targets, predictions)\n",
        "\n",
        "    logs = {}\n",
        "    for metric in metrics:\n",
        "        metric.update_state(targets, predictions)\n",
        "        logs[\"val_\" + metric.name] = metric.result()\n",
        "\n",
        "    loss_tracking_metric.update_state(loss)\n",
        "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
        "    return logs\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
        "val_dataset = val_dataset.batch(32)\n",
        "reset_metrics()\n",
        "for inputs_batch, targets_batch in val_dataset:\n",
        "    logs = test_step(inputs_batch, targets_batch)\n",
        "print(\"Evaluation results:\")\n",
        "for key, value in logs.items():\n",
        "    print(f\"...{key}: {value:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COLa0--jIfu_"
      },
      "source": [
        "### Make it fast with `tf.function`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urVbWgOJIfu_"
      },
      "source": [
        "**Adding a `tf.function` decorator to our evaluation step function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UVXdLgazIfu_"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def test_step(inputs, targets):\n",
        "    predictions = model(inputs, training=False)\n",
        "    loss = loss_fn(targets, predictions)\n",
        "\n",
        "    logs = {}\n",
        "    for metric in metrics:\n",
        "        metric.update_state(targets, predictions)\n",
        "        logs[\"val_\" + metric.name] = metric.result()\n",
        "\n",
        "    loss_tracking_metric.update_state(loss)\n",
        "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
        "    return logs\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
        "val_dataset = val_dataset.batch(32)\n",
        "reset_metrics()\n",
        "for inputs_batch, targets_batch in val_dataset:\n",
        "    logs = test_step(inputs_batch, targets_batch)\n",
        "print(\"Evaluation results:\")\n",
        "for key, value in logs.items():\n",
        "    print(f\"...{key}: {value:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVQ0h6BwIfu_"
      },
      "source": [
        "### Leveraging `fit()` with a custom training loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwfIaa7LIfu_"
      },
      "source": [
        "**Implementing a custom training step to use with `fit()`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8I9sEElTIfu_"
      },
      "outputs": [],
      "source": [
        "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
        "loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
        "\n",
        "class CustomModel(keras.Model):\n",
        "    def train_step(self, data):\n",
        "        inputs, targets = data\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self(inputs, training=True)\n",
        "            loss = loss_fn(targets, predictions)\n",
        "        gradients = tape.gradient(loss, model.trainable_weights)\n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
        "\n",
        "        loss_tracker.update_state(loss)\n",
        "        return {\"loss\": loss_tracker.result()}\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [loss_tracker]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVNI-G9WIfu_"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(28 * 28,))\n",
        "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
        "features = layers.Dropout(0.5)(features)\n",
        "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
        "model = CustomModel(inputs, outputs)\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.RMSprop())\n",
        "model.fit(train_images, train_labels, epochs=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeM4q5qCIfu_"
      },
      "outputs": [],
      "source": [
        "class CustomModel(keras.Model):\n",
        "    def train_step(self, data):\n",
        "        inputs, targets = data\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self(inputs, training=True)\n",
        "            loss = self.compiled_loss(targets, predictions)\n",
        "        gradients = tape.gradient(loss, model.trainable_weights)\n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
        "        self.compiled_metrics.update_state(targets, predictions)\n",
        "        return {m.name: m.result() for m in self.metrics}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgCvmU-GIfu_"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(28 * 28,))\n",
        "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
        "features = layers.Dropout(0.5)(features)\n",
        "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
        "model = CustomModel(inputs, outputs)\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
        "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
        "model.fit(train_images, train_labels, epochs=3)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "dlp07_working_with_keras",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}